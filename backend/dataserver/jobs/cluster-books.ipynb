{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright Â© 2019 Sunho Kim. All rights reserved.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gorani/gorani/backend/dataserver\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('Cluster Books')\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 2\n",
    "iteration = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import CountVectorizer, Normalizer\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "\n",
    "from gorani.spark import read_data_all, write_data\n",
    "from gorani.utils import sparse_to_array\n",
    "\n",
    "SIMILARITY_TYPE = 'cosine'\n",
    "\n",
    "words = read_data_all(spark, 'words', cache = True)\n",
    "books = read_data_all(spark, 'books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\\\n",
    "    .setInputCol('content')\\\n",
    "    .setOutputCol('tf')\\\n",
    "    .setVocabSize(words.count())\n",
    "cv = cv.fit(books)\n",
    "\n",
    "nor = Normalizer()\\\n",
    "    .setInputCol('tf')\\\n",
    "    .setOutputCol('norm')\n",
    "\n",
    "# normalized book-wordcount matrix\n",
    "tf_mat = nor.transform(cv.transform(books))\n",
    "\n",
    "# convert to SparseMatrix to BlockMatrix\n",
    "mat = IndexedRowMatrix(\n",
    "tf_mat.select(\"id\", \"norm\")\\\n",
    "    .rdd.map(lambda row: IndexedRow(row['id'], row['norm'].toArray())))\\\n",
    "    .toBlockMatrix()\n",
    "\n",
    "# cosine similarity\n",
    "sim_mat_df = mat.multiply(mat.transpose())\\\n",
    "    .toIndexedRowMatrix()\\\n",
    "    .rows.toDF()\n",
    "\n",
    "# change schema\n",
    "sim_af = sim_mat_df.select(F.col('index').alias('id'), F.posexplode(sparse_to_array('vector')))\\\n",
    "    .select('id', F.col('pos').alias('other_id'), F.col('col').alias('value'))\\\n",
    "    .where('id < other_id AND id != 0')\\\n",
    "    .rdd.map(lambda x: tuple([x['id'], x['other_id'], float(x['value'])]))\n",
    "print('sim mat:')\n",
    "print(sim_af.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:\n",
      "(id cluster)\n",
      "(4 1)\n",
      "(1 0)\n",
      "(6 1)\n",
      "(3 1)\n",
      "(5 1)\n",
      "(2 0)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import PowerIterationClustering, PowerIterationClusteringModel\n",
    "from pyspark.sql import Row\n",
    "\n",
    "model = PowerIterationClustering.train(sim_af, k, iteration)\n",
    "df = model.assignments().toDF()\n",
    "\n",
    "write_data('cluster_books', df)\n",
    "write_data('book_cluster', df)\n",
    "\n",
    "result = model.assignments().collect()\n",
    "print('result:')\n",
    "print('(id cluster)')\n",
    "for item in result:\n",
    "    print('(' + str(item.id) + ' ' + str(item.cluster) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
